#!/usr/bin/env python3
"""
Script de diagnostic pour identifier le probl√®me de r√©ponse vide avec StarCoder2
Teste diff√©rentes configurations et approches
"""
import asyncio
import aiohttp
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional

# Configuration du logging d√©taill√©
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class OllamaDiagnostic:
    """Outil de diagnostic pour les probl√®mes Ollama"""
    
    def __init__(self, ollama_host: str = "http://localhost:11434"):
        self.ollama_host = ollama_host
        self.session = None
        self.results = []
        
    async def initialize(self):
        """Initialise la session HTTP"""
        self.session = aiohttp.ClientSession()
        logger.info(f"Session initialis√©e pour {self.ollama_host}")
        
    async def run_diagnostics(self):
        """Lance tous les tests de diagnostic"""
        print("\n" + "="*60)
        logger.info("üîç DIAGNOSTIC OLLAMA - STARCODER2")
        print("="*60)
        
        # 1. Test de connectivit√©
        await self.test_connectivity()
        
        # 2. Lister les mod√®les disponibles
        await self.list_models()
        
        # 3. Tester diff√©rents mod√®les StarCoder
        await self.test_starcoder_variants()
        
        # 4. Tester diff√©rentes APIs
        await self.test_api_endpoints()
        
        # 5. Tester diff√©rents formats de prompt
        await self.test_prompt_formats()
        
        # 6. Tester les param√®tres
        await self.test_parameters()
        
        # 7. Afficher le r√©sum√©
        self.print_summary()
        
    async def test_connectivity(self):
        """Test de base de la connectivit√© Ollama"""
        logger.info("\n1Ô∏è‚É£ Test de connectivit√©")
        print("-" * 40)
        
        try:
            async with self.session.get(f"{self.ollama_host}/") as resp:
                if resp.status == 200:
                    logger.info("‚úÖ Ollama accessible")
                    self.results.append(("Connectivit√©", "OK", None))
                else:
                    logger.info(f"‚ùå Status: {resp.status}")
                    self.results.append(("Connectivit√©", "FAIL", f"Status {resp.status}"))
        except Exception as e:
            logger.info(f"‚ùå Erreur de connexion: {e}")
            self.results.append(("Connectivit√©", "FAIL", str(e)))
            
    async def list_models(self):
        """Liste tous les mod√®les disponibles"""
        logger.info("\n2Ô∏è‚É£ Mod√®les disponibles")
        print("-" * 40)
        
        try:
            async with self.session.get(f"{self.ollama_host}/api/tags") as resp:
                if resp.status == 200:
                    data = await resp.json()
                    models = data.get('models', [])
                    
                    starcoder_models = []
                    for model in models:
                        name = model.get('name', '')
                        if 'starcoder' in name.lower() or 'star' in name.lower():
                            starcoder_models.append(name)
                            logger.info(f"  üåü {name} ({model.get('size', 'N/A')})")
                        else:
                            logger.info(f"  ‚Ä¢ {name}")
                    
                    self.results.append(("Mod√®les trouv√©s", f"{len(models)}", 
                                       f"StarCoder: {len(starcoder_models)}"))
                    return starcoder_models
        except Exception as e:
            logger.info(f"‚ùå Erreur: {e}")
            self.results.append(("Liste mod√®les", "FAIL", str(e)))
        return []
        
    async def test_starcoder_variants(self):
        """Teste diff√©rentes variantes de StarCoder"""
        logger.info("\n3Ô∏è‚É£ Test des variantes StarCoder")
        print("-" * 40)
        
        variants = [
            "starcoder2-playwright",
            "starcoder2:15b-q8_0",
            "starcoder:3b",
            "starcoder2",
            "starcoder"
        ]
        
        for variant in variants:
            success = await self.test_single_model(variant)
            if success:
                logger.info(f"  ‚úÖ {variant} - Fonctionne")
            else:
                logger.info(f"  ‚ùå {variant} - √âchec")
                
    async def test_single_model(self, model_name: str) -> bool:
        """Teste un mod√®le sp√©cifique"""
        try:
            # Test simple avec /api/generate
            payload = {
                "model": model_name,
                "prompt": "def hello():\n    return",
                "stream": False,
                "options": {"num_predict": 20}
            }
            
            async with self.session.post(
                f"{self.ollama_host}/api/generate",
                json=payload,
                timeout=aiohttp.ClientTimeout(total=10)
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    response = data.get("response", "")
                    if response:
                        self.results.append((f"Mod√®le {model_name}", "OK", 
                                           f"{len(response)} chars"))
                        return True
                    else:
                        self.results.append((f"Mod√®le {model_name}", "EMPTY", 
                                           "R√©ponse vide"))
                else:
                    self.results.append((f"Mod√®le {model_name}", "FAIL", 
                                       f"Status {resp.status}"))
        except asyncio.TimeoutError:
            self.results.append((f"Mod√®le {model_name}", "TIMEOUT", "10s"))
        except Exception as e:
            self.results.append((f"Mod√®le {model_name}", "ERROR", str(e)[:50]))
        return False
        
    async def test_api_endpoints(self):
        """Teste les diff√©rents endpoints API"""
        logger.info("\n4Ô∏è‚É£ Test des endpoints API")
        print("-" * 40)
        
        # Trouver un mod√®le qui marche
        test_model = "starcoder2:15b-q8_0"  # Par d√©faut
        
        # Test /api/generate
        logger.info("\n  üìç Test /api/generate:")
        response_gen = await self.test_generate_api(test_model)
        
        # Test /api/chat
        logger.info("\n  üìç Test /api/chat:")
        response_chat = await self.test_chat_api(test_model)
        
        # Comparer les r√©sultats
        if response_gen and response_chat:
            logger.info(f"\n  üìä Comparaison:")
            logger.info(f"     Generate: {len(response_gen)} caract√®res")
            logger.info(f"     Chat: {len(response_chat)} caract√®res")
            
    async def test_generate_api(self, model: str) -> Optional[str]:
        """Teste l'API /generate"""
        payloads = [
            # Format basique
            {
                "model": model,
                "prompt": "Generate a simple Playwright test:\n```python\n",
                "stream": False
            },
            # Avec system
            {
                "model": model,
                "prompt": "Generate a simple Playwright test",
                "system": "You are a Python test automation expert.",
                "stream": False
            },
            # Avec options compl√®tes
            {
                "model": model,
                "prompt": "# Playwright test for login\ndef test_login(page):\n",
                "stream": False,
                "options": {
                    "temperature": 0.2,
                    "num_predict": 200,
                    "stop": ["```", "\n\n\n"]
                }
            }
        ]
        
        for i, payload in enumerate(payloads):
            try:
                logger.debug(f"Test payload {i+1}: {json.dumps(payload, indent=2)}")
                
                async with self.session.post(
                    f"{self.ollama_host}/api/generate",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as resp:
                    raw = await resp.text()
                    logger.debug(f"Raw response: {raw[:200]}")
                    
                    if resp.status == 200:
                        data = json.loads(raw)
                        response = data.get("response", "")
                        if response:
                            logger.info(f"    ‚úÖ Format {i+1}: {len(response)} chars")
                            self.results.append((f"Generate format {i+1}", "OK", 
                                               f"{len(response)} chars"))
                            return response
                        else:
                            logger.info(f"    ‚ùå Format {i+1}: R√©ponse vide")
                            logger.debug(f"Cl√©s disponibles: {list(data.keys())}")
                    else:
                        logger.info(f"    ‚ùå Format {i+1}: Status {resp.status}")
            except Exception as e:
                logger.info(f"    ‚ùå Format {i+1}: {type(e).__name__}")
                logger.error(f"Erreur: {e}")
        
        return None
        
    async def test_chat_api(self, model: str) -> Optional[str]:
        """Teste l'API /chat"""
        payloads = [
            # Format simple
            {
                "model": model,
                "messages": [
                    {"role": "user", "content": "Generate a Playwright test for login"}
                ],
                "stream": False
            },
            # Avec system message
            {
                "model": model,
                "messages": [
                    {"role": "system", "content": "You are a test automation expert."},
                    {"role": "user", "content": "Write a Playwright test"}
                ],
                "stream": False
            },
            # Avec options
            {
                "model": model,
                "messages": [
                    {"role": "user", "content": "Create async def test_example(page):"}
                ],
                "stream": False,
                "options": {"temperature": 0.2, "num_predict": 200}
            }
        ]
        
        for i, payload in enumerate(payloads):
            try:
                async with self.session.post(
                    f"{self.ollama_host}/api/chat",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        content = data.get("message", {}).get("content", "")
                        if content:
                            logger.info(f"    ‚úÖ Format {i+1}: {len(content)} chars")
                            self.results.append((f"Chat format {i+1}", "OK", 
                                               f"{len(content)} chars"))
                            return content
                        else:
                            logger.info(f"    ‚ùå Format {i+1}: Contenu vide")
                    else:
                        logger.info(f"    ‚ùå Format {i+1}: Status {resp.status}")
            except Exception as e:
                logger.info(f"    ‚ùå Format {i+1}: {type(e).__name__}")
                
        return None
        
    async def test_prompt_formats(self):
        """Teste diff√©rents formats de prompts"""
        logger.info("\n5Ô∏è‚É£ Test des formats de prompt")
        print("-" * 40)
        
        model = "starcoder2:15b-q8_0"  # Utiliser le mod√®le de base
        
        prompts = [
            # Code completion style
            ("Code completion", "def test_login(page):\n    # Test login functionality\n    "),
            
            # Instruction style
            ("Instruction", "Write a Playwright test function that checks if a button is clickable"),
            
            # Markdown style
            ("Markdown", "```python\n# Playwright test\nasync def test_"),
            
            # Comment style
            ("Comment", "# TODO: Create a Playwright test for form submission\n# The test should:\n# 1. Navigate to /form\n# 2. Fill the form\n# 3. Submit\n\ndef test_"),
            
            # Template style
            ("Template", "[INST] Generate a Playwright test [/INST]\n"),
        ]
        
        for name, prompt in prompts:
            logger.info(f"\n  üß™ Test: {name}")
            response = await self.test_prompt_response(model, prompt)
            if response:
                logger.info(f"    ‚úÖ R√©ponse: {len(response)} caract√®res")
                logger.info(f"    üìù Extrait: {response[:100]}...")
            else:
                logger.info(f"    ‚ùå Pas de r√©ponse")
                
    async def test_prompt_response(self, model: str, prompt: str) -> Optional[str]:
        """Teste un prompt sp√©cifique"""
        try:
            payload = {
                "model": model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,
                    "num_predict": 100
                }
            }
            
            async with self.session.post(
                f"{self.ollama_host}/api/generate",
                json=payload,
                timeout=aiohttp.ClientTimeout(total=15)
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    return data.get("response", "")
        except Exception as e:
            logger.error(f"Erreur test prompt: {e}")
        return None
        
    async def test_parameters(self):
        """Teste diff√©rentes combinaisons de param√®tres"""
        logger.info("\n6Ô∏è‚É£ Test des param√®tres")
        print("-" * 40)
        
        model = "starcoder2:15b-q8_0"
        base_prompt = "def calculate_sum(a, b):\n    "
        
        param_sets = [
            {"name": "Default", "params": {}},
            {"name": "Low temp", "params": {"temperature": 0.1}},
            {"name": "High predict", "params": {"num_predict": 500}},
            {"name": "With seed", "params": {"seed": 42, "temperature": 0.2}},
            {"name": "Full context", "params": {"num_ctx": 4096, "num_predict": 200}},
        ]
        
        for param_set in param_sets:
            logger.info(f"\n  ‚öôÔ∏è {param_set['name']}: ", end="")
            
            try:
                payload = {
                    "model": model,
                    "prompt": base_prompt,
                    "stream": False,
                    "options": param_set['params']
                }
                
                async with self.session.post(
                    f"{self.ollama_host}/api/generate",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=20)
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        response = data.get("response", "")
                        if response:
                            logger.info(f"‚úÖ {len(response)} chars")
                            self.results.append((f"Params: {param_set['name']}", 
                                               "OK", f"{len(response)} chars"))
                        else:
                            logger.info("‚ùå R√©ponse vide")
                            self.results.append((f"Params: {param_set['name']}", 
                                               "EMPTY", "0 chars"))
                    else:
                        logger.info(f"‚ùå Status {resp.status}")
            except Exception as e:
                logger.info(f"‚ùå {type(e).__name__}")
                
    def print_summary(self):
        """Affiche un r√©sum√© des r√©sultats"""
        print("\n" + "="*60)
        logger.info("üìä R√âSUM√â DU DIAGNOSTIC")
        print("="*60)
        
        # Statistiques
        total_tests = len(self.results)
        successful = sum(1 for _, status, _ in self.results if status == "OK")
        failed = sum(1 for _, status, _ in self.results if status in ["FAIL", "ERROR"])
        empty = sum(1 for _, status, _ in self.results if status == "EMPTY")
        
        logger.info(f"\nüìà Statistiques:")
        logger.info(f"  ‚Ä¢ Tests totaux: {total_tests}")
        logger.info(f"  ‚Ä¢ ‚úÖ R√©ussis: {successful}")
        logger.info(f"  ‚Ä¢ ‚ùå √âchou√©s: {failed}")
        logger.info(f"  ‚Ä¢ üì≠ Vides: {empty}")
        
        # Recommandations
        logger.info(f"\nüí° Recommandations:")
        
        if empty > 0:
            logger.info("  1. Le probl√®me de r√©ponse vide est confirm√©")
            logger.info("  2. Essayer l'API /chat au lieu de /generate")
            logger.info("  3. V√©rifier les logs Ollama: journalctl -u ollama -f")
            
        if successful > 0:
            logger.info("  4. Certaines configurations fonctionnent")
            logger.info("  5. Utiliser les param√®tres qui ont r√©ussi")
            
        # D√©tails des √©checs
        if failed > 0 or empty > 0:
            logger.info(f"\n‚ö†Ô∏è D√©tails des probl√®mes:")
            for test, status, detail in self.results:
                if status in ["FAIL", "ERROR", "EMPTY"]:
                    logger.info(f"  ‚Ä¢ {test}: {status} - {detail}")
                    
    async def close(self):
        """Ferme la session"""
        if self.session:
            await self.session.close()


# Fonction principale
async def main():
    """Lance le diagnostic complet"""
    diagnostic = OllamaDiagnostic()
    
    try:
        await diagnostic.initialize()
        await diagnostic.run_diagnostics()
    except Exception as e:
        logger.error(f"Erreur fatale: {e}", exc_info=True)
    finally:
        await diagnostic.close()
        
    logger.info("\n‚úÖ Diagnostic termin√©")
    logger.info(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    logger.info("üöÄ Lancement du diagnostic Ollama/StarCoder2")
    logger.info("Cela peut prendre quelques minutes...")
    asyncio.run(main())
