#!/usr/bin/env python3
"""
Interface Qwen3 avec Ollama pour l'analyse de SFD
Optimis√©e pour g√©n√©ration de sc√©narios de test sur CPU
Support du context 32K tokens pour documents longs
"""
from __future__ import annotations
import asyncio
import hashlib
import json
import logging
from datetime import datetime
from typing import Dict, Optional, List
import aiohttp





# Import pour l'√©volution de la personnalit√©
from psychodesign.personality_evolution import PersonalityEvolution
from src.models.sfd_models import SFDAnalysisRequest
from src.utils.circuit_breaker import CircuitBreaker



logger = logging.getLogger(__name__)


class Qwen3OllamaInterface:
    """
    Interface pour communiquer avec Qwen3 via Ollama
    Sp√©cialis√©e dans l'analyse de sp√©cifications fonctionnelles
    """

    def __init__(self,
                 model_name: str = "qwen3-sfd-analyzer",
                 ollama_host: str = "http://localhost:11434",
                 timeout: int = 120,
                 cache_enabled: bool = True,
                 failure_threshold: int = 5,
                 recovery_timeout: int = 60):
        self.model_name = model_name
        self.ollama_host = ollama_host
        self.timeout = timeout
        self.cache_enabled: bool = cache_enabled
        self.session = None
        self.adapter_path: Optional[str] = None
        self.personality_evolver = PersonalityEvolution()
        self.circuit_breaker = CircuitBreaker(failure_threshold, recovery_timeout)

        # Cache en m√©moire pour √©viter les re-analyses
        self.cache: Dict[str, Dict] = {}

        # Configuration sp√©cifique Qwen3
        self.default_params = {
            "temperature": 0.7,
            "top_p": 0.9,
            "top_k": 40,
            "repeat_penalty": 1.1,
            "num_ctx": 32768,  # Context 32K
            "num_predict": 4096
        }

    async def initialize(self):
        """Initialise la session HTTP et v√©rifie le mod√®le"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=self.timeout)
        )

        # V√©rifier que le mod√®le est disponible
        if not await self._check_model():
            raise RuntimeError(f"Mod√®le {self.model_name} non disponible dans Ollama")

        # Pr√©charger le mod√®le pour √©viter la latence au premier appel
        await self._preload_model()

        # Charger le dernier adaptateur de personnalit√© LoRA
        self.load_latest_adapter()

        logger.info(f"Interface Qwen3 initialis√©e avec mod√®le {self.model_name}")

    async def _check_model(self) -> bool:
        """V√©rifie la disponibilit√© du mod√®le via le circuit breaker"""
        async def _do_check():
            async with self.session.get(f"{self.ollama_host}/api/tags") as resp:
                resp.raise_for_status()  # L√®ve une exception pour les codes d'√©tat HTTP 4xx/5xx
                data = await resp.json()
                models = [m['name'] for m in data.get('models', [])]
                return any(self.model_name in model for model in models)

        try:
            return await self.circuit_breaker.call(_do_check)
        except Exception as e:
            logger.error(f"Erreur v√©rification mod√®le (via circuit breaker): {e}")
            return False

    async def _preload_model(self):
        """Pr√©charge le mod√®le en m√©moire pour r√©duire la latence via le circuit breaker"""
        logger.info("Pr√©chargement du mod√®le Qwen3...")

        async def _do_preload():
            payload = {
                "model": self.model_name,
                "prompt": "Bonjour",
                "stream": False,
                "options": {"num_predict": 1}
            }
            async with self.session.post(
                    f"{self.ollama_host}/api/generate",
                    json=payload
            ) as resp:
                resp.raise_for_status()  # L√®ve une exception pour les codes d'√©tat HTTP 4xx/5xx
                await resp.json()

        try:
            await self.circuit_breaker.call(_do_preload)
            logger.info("Mod√®le pr√©charg√© avec succ√®s")
        except Exception as e:
            logger.warning(f"Pr√©chargement √©chou√© (non critique, via circuit breaker): {e}")

    def load_latest_adapter(self):
        """Charge le chemin du dernier adaptateur LoRA disponible."""
        latest_adapter_path = self.personality_evolver.get_latest_adapter()
        if latest_adapter_path and latest_adapter_path.exists():
            self.adapter_path = str(latest_adapter_path)
            logger.info(f"üß† Adaptateur de personnalit√© LoRA charg√© : {self.adapter_path}")
        else:
            logger.info("üß† Aucun adaptateur de personnalit√© trouv√©, utilisation du mod√®le de base.")

    async def analyze_sfd(self,
                          request: SFDAnalysisRequest,
                          use_cache: bool = True) -> Dict:
        """
        Analyse un SFD et extrait les sc√©narios de test via le circuit breaker

        Args:
            request: Objet SFDAnalysisRequest contenant le contenu et le type d'extraction.
            use_cache: Utiliser le cache si disponible

        Returns:
            Dict contenant les sc√©narios extraits et m√©tadonn√©es
        """
        # CORRECTION 2: Initialiser cache_key avant utilisation
        cache_key = self._generate_cache_key(request.content, request.extraction_type)

        # V√©rifier le cache si activ√©
        if use_cache and self.cache_enabled and cache_key in self.cache:
            logger.info("R√©sultat trouv√© dans le cache")
            return self.cache[cache_key]

        # Construire le prompt selon le type d'extraction
        prompt = self._build_analysis_prompt(request.content, request.extraction_type)

        # Param√®tres optimis√©s pour l'analyse
        params = self.default_params.copy()
        if request.extraction_type == "critical":
            params["temperature"] = 0.3  # Plus d√©terministe pour les cas critiques

        # Appel au mod√®le
        start_time = asyncio.get_event_loop().time()

        async def _do_analyze():
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "format": "json",  # Force la sortie JSON
                "options": params
            }

            # Ajouter l'adaptateur LoRA si disponible
            if self.adapter_path:
                payload["adapter"] = self.adapter_path

            async with self.session.post(
                    f"{self.ollama_host}/api/generate",
                    json=payload
            ) as resp:
                resp.raise_for_status()  # L√®ve une exception pour les codes d'√©tat HTTP 4xx/5xx
                data = await resp.json()

                # CORRECTION 3: V√©rifier la r√©ponse vide
                if not data or not data.get("response"):
                    logger.error("R√©ponse vide d'Ollama")
                    return {"scenarios": [], "error": "empty_response"}

                response = data.get("response", "{}")

                # Parser et valider la r√©ponse JSON
                result = self._parse_analysis_response(response)

                # Ajouter les m√©tadonn√©es
                result["metadata"] = {
                    "processing_time": asyncio.get_event_loop().time() - start_time,
                    "model": self.model_name,
                    "adapter": self.adapter_path,
                    "extraction_type": request.extraction_type,
                    "content_length": len(request.content),
                    "timestamp": datetime.now().isoformat()
                }

                # Mettre en cache si activ√©
                if use_cache and self.cache_enabled:
                    self.cache[cache_key] = result

                return result

        try:
            return await self.circuit_breaker.call(_do_analyze)
        except asyncio.TimeoutError:
            raise Exception(f"Timeout apr√®s {self.timeout}s - Document trop long?")
        except Exception as e:
            logger.error(f"Erreur analyse SFD (via circuit breaker): {e}")
            raise

    @staticmethod
    def _generate_cache_key(content: str, extraction_type: str) -> str:
        """G√©n√®re une cl√© de cache unique"""
        content_hash = hashlib.md5(content.encode()).hexdigest()
        return f"qwen3_analysis_{extraction_type}_{content_hash}"

    @staticmethod
    def _build_analysis_prompt(content: str, extraction_type: str) -> str:
        """Construit le prompt selon le type d'extraction demand√©"""

        # Limiter la taille du contenu si n√©cessaire (32K tokens max)
        # Approximation : 1 token ‚âà 4 caract√®res
        max_chars = 120000  # ~30K tokens pour garder de la marge
        if len(content) > max_chars:
            content = content[:max_chars] + "\n... [Document tronqu√©]"

        prompts = {
            "complete": """En tant qu'expert en test logiciel, analyse cette sp√©cification fonctionnelle et extrais TOUS les sc√©narios de test possibles.\n\nPour chaque sc√©nario, fournis au format JSON:\n- titre: Nom descriptif du test\n- objectif: But du test\n- criticite: HAUTE/MOYENNE/BASSE\n- preconditions: Liste des pr√©requis\n- etapes: Liste d√©taill√©e des √©tapes\n- resultat_attendu: Description du r√©sultat\n- donnees_test: Donn√©es n√©cessaires\n- type_test: FONCTIONNEL/INTEGRATION/E2E/SECURITE/PERFORMANCE\n\nSp√©cification:\n{content}\n\nG√©n√®re la r√©ponse au format JSON valide avec une structure "scenarios": []""",

            "summary": """Analyse cette sp√©cification et identifie les 10 sc√©narios de test les plus importants.\nFocus sur les fonctionnalit√©s critiques et les cas d'usage principaux.\n\nSp√©cification:\n{content}\n\nFormat JSON avec "scenarios": [] contenant les 10 tests prioritaires.""",

            "critical": """Identifie UNIQUEMENT les sc√©narios de test CRITIQUES pour la s√©curit√©, les donn√©es sensibles et les processus m√©tier essentiels.\n\nSp√©cification:\n{content}\n\nFormat JSON avec "scenarios": [] contenant uniquement les tests de criticit√© HAUTE."""
        }

        prompt_template = prompts.get(extraction_type, prompts["complete"])
        return prompt_template.format(content=content)

    @staticmethod
    def _parse_analysis_response(response: str) -> Dict:
        """Parse et valide la r√©ponse JSON du mod√®le"""
        try:
            # Nettoyer la r√©ponse si n√©cessaire
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.endswith("```"):
                response = response[:-3]

            # Parser le JSON
            data = json.loads(response)

            # Valider la structure
            if "scenarios" not in data:
                data = {"scenarios": []}

            # Enrichir les sc√©narios avec des valeurs par d√©faut
            for scenario in data["scenarios"]:
                scenario.setdefault("criticite", "MOYENNE")
                scenario.setdefault("type_test", "FONCTIONNEL")
                scenario.setdefault("preconditions", [])
                scenario.setdefault("donnees_test", {})

            return data

        except json.JSONDecodeError as e:
            logger.error(f"Erreur parsing JSON: {e}. R√©ponse brute: {response}")
            # Retourner une structure vide en cas d'erreur
            return {
                "scenarios": [],
                "error": "Erreur de parsing de la r√©ponse",
                "raw_response": response
            }

    async def generate_test_matrix(self, scenarios: List[Dict]) -> Dict:
        """
        G√©n√®re une matrice de tests structur√©e √† partir des sc√©narios via le circuit breaker
        Optimis√© pour export Excel
        """
        prompt = f"""Cr√©e une matrice de tests structur√©e pour Excel √† partir de ces sc√©narios:\n\n{json.dumps(scenarios, ensure_ascii=False, indent=2)}\n\nLa matrice doit inclure:\n- ID unique par test\n- Module/Fonctionnalit√©\n- Sc√©nario\n- Priorit√© (P1/P2/P3)\n- Complexit√© (Simple/Moyenne/Complexe)\n- Effort estim√© (heures)\n- D√©pendances\n- Automatisable (Oui/Non/Partiel)\n\nFormat JSON avec structure "test_matrix": []"""

        async def _do_generate():
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "format": "json",
                "options": {
                    **self.default_params,
                    "temperature": 0.5  # Plus structur√©
                }
            }

            async with self.session.post(
                    f"{self.ollama_host}/api/generate",
                    json=payload
            ) as resp:
                resp.raise_for_status()  # L√®ve une exception pour les codes d'√©tat HTTP 4xx/5xx
                data = await resp.json()

                # V√©rifier la r√©ponse vide ici aussi
                if not data or not data.get("response"):
                    logger.error("R√©ponse vide d'Ollama pour la matrice")
                    return {"test_matrix": [], "error": "empty_response"}

                return self._parse_analysis_response(data.get("response", "{}"))

        try:
            return await self.circuit_breaker.call(_do_generate)
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration matrice (via circuit breaker): {e}")
            raise

    async def close(self):
        """Ferme la session HTTP"""
        if self.session:
            await self.session.close()
        logger.info("Interface Qwen3 ferm√©e")


# Exemple d'utilisation
async def main():
    """D√©monstration de l'interface Qwen3"""
    interface = Qwen3OllamaInterface()

    try:
        await interface.initialize()

        # Exemple d'analyse de SFD
        sfd_example = """
        Sp√©cification Fonctionnelle: Module de Paiement

        1. Authentification s√©curis√©e
        - L'utilisateur doit s'authentifier avec email/mot de passe
        - Support de l'authentification √† deux facteurs

        2. Processus de paiement
        - S√©lection du mode de paiement (CB, PayPal, virement)
        - Validation des informations
        - Confirmation avec code OTP
        """

        # Analyse compl√®te
        sfd_request = SFDAnalysisRequest(content=sfd_example, extraction_type="complete")
        result = await interface.analyze_sfd(
            request=sfd_request
        )

        print(f"Analyse termin√©e en {result['metadata']['processing_time']:.2f}s")
        print(f"Sc√©narios extraits: {len(result['scenarios'])}")

        for scenario in result['scenarios']:
            print(f"  - {scenario['titre']} [{scenario['criticite']}]")

    finally:
        await interface.close()


if __name__ == "__main__":
    asyncio.run(main())
