{
  "model_name": "qwen3:32b-q4_K_M",
  "model_type": "causal_lm",
  "dataset_path": "data/playwright_training_data.jsonl",
  "output_dir": "models/qwen3:32b-q4_K_M-finetuned",
  "# Optimisations CPU i5 13gen": null,
  "device": "cpu",
  "num_threads": 12,
  "use_compile": true,
  "# Configuration LoRA pour \u00e9conomie m\u00e9moire": null,
  "use_lora": true,
  "lora_r": 32,
  "lora_alpha": 64,
  "lora_dropout": 0.1,
  "lora_target_modules": [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj",
    "gate_proj",
    "up_proj",
    "down_proj"
  ],
  "# Hyperparam\u00e8tres d'entra\u00eenement": null,
  "batch_size": 1,
  "gradient_accumulation_steps": 16,
  "learning_rate": 2e-5,
  "per_device_train_batch_size": 2,
  "num_train_epochs": 3,
  "max_seq_length":4096,
  "warmup_ratio": 0.1,
  "weight_decay": 0.01,
  "# Optimisations m\u00e9moire": null,
  "gradient_checkpointing": true,
  "mixed_precision": "no",
  "bf16": true,
  "optim": "adamw_torch_fused",
  "tf32": false,
  "# Sauvegarde et \u00e9valuation": null,
  "save_steps": 100,
  "eval_steps": 50,
  "save_total_limit": 3,
  "load_best_model_at_end": true,
  "metric_for_best_model": "eval_loss",
  "# Logging": null,
  "logging_steps": 10,
  "report_to": [
    "tensorboard"
  ],
  "logging_dir": "./logs"
}